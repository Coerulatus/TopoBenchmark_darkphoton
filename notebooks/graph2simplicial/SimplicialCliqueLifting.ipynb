{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimplicialCliqueLifting Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(\"./\", indicator=\".project-root\", pythonpath=True)\n",
    "root_folder = rootutils.find_root()\n",
    "import omegaconf\n",
    "\n",
    "from topobenchmarkx.data.load.loaders import GraphLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either we keep yaml config files and provide a brief overview of them, or we build the required config files by hand in these tutorials. (I prefer the former option.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_domain': 'graph', 'data_type': 'cocitation', 'data_name': 'Cora', 'data_dir': '/Users/gbg141/Documents/TopoProjectX/TopoBenchmarkX/datasets/graph/cocitation', 'data_split_dir': '/Users/gbg141/Documents/TopoProjectX/TopoBenchmarkX/datasets/graph/cocitation/data_splits/Cora', 'num_features': 1433, 'num_classes': 7, 'task': 'classification', 'loss_type': 'cross_entropy', 'monitor_metric': 'accuracy', 'task_level': 'node', 'data_seed': 0, 'split_type': 'random', 'k': 10, 'train_prop': 0.5, 'batch_size': 1, 'num_workers': 1, 'pin_memory': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"cocitation_cora\"\n",
    "dataset_config = omegaconf.OmegaConf.load(\n",
    "    f\"{root_folder}/configs/dataset/{dataset_name}.yaml\"\n",
    ").parameters\n",
    "#################################################################################################################\n",
    "# Need to interpolate a couple of paths by hand for now; will be solved when we generate the challenge repository:\n",
    "dataset_config[\"data_dir\"] = (\n",
    "    f\"{root_folder}/datasets/{dataset_config['data_domain']}/{dataset_config['data_type']}\"\n",
    ")\n",
    "dataset_config[\"data_split_dir\"] = (\n",
    "    f\"{dataset_config['data_dir']}/data_splits/{dataset_config['data_name']}\"\n",
    ")\n",
    "#################################################################################################################\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transform Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same dilemma as before, yaml files or dicts within tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifting': {'_target_': 'topobenchmarkx.transforms.data_transform.DataTransform', 'transform_type': 'lifting', 'transform_name': 'SimplicialCliqueLifting', 'complex_dim': '${oc.select:dataset.parameters.max_dim_if_lifted,2}', 'preserve_edge_attr': '${oc.select:dataset.parameters.preserve_edge_attr_if_lifted,False}', 'signed': True, 'feature_lifting': 'ProjectionSum'}}\n"
     ]
    }
   ],
   "source": [
    "lifting_type = \"graph2simplicial\"\n",
    "id_lifting = \"simplicial_clique\"\n",
    "transform_config = {\n",
    "    \"lifting\": omegaconf.OmegaConf.load(\n",
    "        f\"{root_folder}/configs/dataset/transforms/{lifting_type}_lifting/{id_lifting}.yaml\"\n",
    "    )\n",
    "    # other transforms (e.g. data manipulations, feature liftings) can be added here\n",
    "}\n",
    "print(transform_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Transform the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform parameters are the same, using existing data_dir: /Users/gbg141/Documents/TopoProjectX/TopoBenchmarkX/datasets/graph/cocitation/Cora/lifting/4278182681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbg141/Documents/TopoProjectX/TopoBenchmarkX/venv_topox/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:293: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataset = GraphLoader(dataset_config, transform_config).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from topomodelx.nn.simplicial.san import SAN\n",
    "\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.base_model = SAN(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            n_layers=n_layers,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, laplacian_up, laplacian_down):\n",
    "        x = self.base_model(x, laplacian_up, laplacian_down)\n",
    "        x = self.linear(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "in_channels = dataset_config[\"num_features\"]\n",
    "hidden_channels = 32\n",
    "out_channels = dataset_config[\"num_classes\"]\n",
    "\n",
    "model = Network(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=n_layers,\n",
    ")\n",
    "\n",
    "data = dataset.data_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(data.x_1, data.up_laplacian_1, data.down_laplacian_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
