{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff to load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/usr/local/lib/python3.11/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/usr/local/lib/python3.11/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n"
     ]
    }
   ],
   "source": [
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(\"/TopoBenchmarkX\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import initialize, compose\n",
    "\n",
    "initialize(config_path=\"../configs\", job_name=\"job\")\n",
    "config = compose(config_name=\"train.yaml\", return_hydra_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.utils import to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topobenchmarkx.data.liftings.liftings import HypergraphKHopLifting\n",
    "from topobenchmarkx.data.liftings.lifted_dataset import Transform, LiftedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1], hyperedges=[17, 17])\n"
     ]
    }
   ],
   "source": [
    "data_mutag = torch_geometric.datasets.TUDataset(root=\"../data/graph\", name=\"MUTAG\")\n",
    "list_of_data = [d for d in data_mutag]\n",
    "lift = HypergraphKHopLifting(k=1)\n",
    "transform = Transform(lift)\n",
    "list_of_data = transform.transform(list_of_data)\n",
    "\n",
    "# lifted_mutag = LiftedDataset(list_of_data)\n",
    "print(data_mutag.get(0))\n",
    "print(list_of_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_mutag.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTAG(188)\n",
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "DataBatch(edge_index=[2, 3632], x=[1658, 7], edge_attr=[3632, 4], y=[94], batch=[1658], ptr=[95], pos=[1658, 7], hyperedges=[1658, 1658])\n",
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "DataBatch(edge_index=[2, 3632], x=[1658, 7], edge_attr=[3632, 4], y=[94], batch=[1658], ptr=[95], pos=[1658, 7], hyperedges=[1658, 1658])\n",
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "DataBatch(edge_index=[2, 3632], x=[1658, 7], edge_attr=[3632, 4], y=[94], batch=[1658], ptr=[95], pos=[1658, 7], hyperedges=[1658, 1658])\n"
     ]
    }
   ],
   "source": [
    "lift = KNearestNeighborsLifting(k=1)\n",
    "\n",
    "n_graphs = len(data_mutag)\n",
    "loader = torch_geometric.loader.DataLoader(data_mutag, batch_size=int(n_graphs / 2))\n",
    "\n",
    "print(data_mutag)\n",
    "\n",
    "for _ in range(3):\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        batch = lift(batch, batch_idx)\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cora(cfg):\n",
    "    data_dir = cfg[\"data_dir\"]\n",
    "    print(f\"Loading {cfg['data_domain']} dataset name: {cfg['data_name']}\")\n",
    "\n",
    "    data = torch_geometric.datasets.Planetoid(data_dir, \"Cora\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hypergraph dataset name: cora\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "\n",
    "data_cora = get_cora(config.data)\n",
    "n_graphs = len(data_cora)\n",
    "loader = torch_geometric.loader.DataLoader(data_cora, batch_size=n_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "Cora()\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(loader):\n",
    "    batch = lift(batch, batch_idx)\n",
    "    print(batch)\n",
    "\n",
    "print(data_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11])\n"
     ]
    }
   ],
   "source": [
    "print(batch.hyperedges.indices()[1][batch.hyperedges.indices()[0] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'readout_workaround' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['readout_workaround'])`.\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'readout' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['readout'])`.\n"
     ]
    }
   ],
   "source": [
    "model = hydra.utils.instantiate(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_lifted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m model(data_lifted\u001b[39m.\u001b[39mx, data_lifted\u001b[39m.\u001b[39mhyperedges)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_lifted' is not defined"
     ]
    }
   ],
   "source": [
    "results = model(data_lifted.x, data_lifted.hyperedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.1128, 0.0000, 0.0000,  ..., 0.0000, 1.0280, 0.0000],\n",
      "        [1.1101, 0.0000, 0.0000,  ..., 0.0000, 0.8908, 0.0000],\n",
      "        [1.2814, 0.0000, 0.0000,  ..., 0.0000, 1.4679, 0.0000],\n",
      "        ...,\n",
      "        [0.8512, 0.0000, 0.0000,  ..., 0.0000, 1.5145, 0.0000],\n",
      "        [1.0093, 0.0000, 0.0000,  ..., 0.0000, 1.0170, 0.0000],\n",
      "        [1.0837, 0.0000, 0.0000,  ..., 0.0000, 0.9484, 0.1635]],\n",
      "       grad_fn=<MulBackward0>), tensor([[0.0000, 0.0000, 0.8117,  ..., 0.0000, 1.9955, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6481,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.2122, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.6992,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8787,  ..., 0.0000, 1.6070, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8623,  ..., 0.0000, 2.3690, 0.0000]],\n",
      "       grad_fn=<MulBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(sys.getsizeof(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
