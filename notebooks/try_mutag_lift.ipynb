{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff to load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/usr/local/lib/python3.11/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/usr/local/lib/python3.11/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n"
     ]
    }
   ],
   "source": [
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(\"/TopoBenchmarkX\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import initialize, compose\n",
    "\n",
    "initialize(config_path=\"../configs\", job_name=\"job\")\n",
    "config = compose(config_name=\"train.yaml\", return_hydra_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.utils import to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import torch_geometric\n",
    "\n",
    "\n",
    "class AbstractLifting(torch_geometric.transforms.BaseTransform):\n",
    "    \"\"\"abstract class that provides an interface to define a custom readout\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        return\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, batch: torch_geometric.data.Batch) -> torch_geometric.data.Batch:\n",
    "        \"\"\"Forward pass of the lifting\n",
    "        \"\"\"\n",
    "        \n",
    "    def __call__(self, batch: torch_geometric.data.Batch, batch_idx):\n",
    "        if batch_idx in self.cache:\n",
    "            return self.cache[batch_idx]\n",
    "        \n",
    "        lifted = self.forward(batch)\n",
    "        self.cache[batch_idx] = lifted\n",
    "        return lifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class KHopLifting(AbstractLifting):\n",
    "    def __init__(self, k=1):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.added_fields = [\"hyperedges\"]\n",
    "\n",
    "    def forward(self, batch: torch_geometric.data.Batch) -> torch_geometric.data.Batch:\n",
    "        data_lifted = copy.copy(batch)\n",
    "\n",
    "        n_nodes = batch.x.shape[0]\n",
    "\n",
    "        incidence_1 = torch.zeros(n_nodes, n_nodes)\n",
    "        edge_index = torch_geometric.utils.to_undirected(batch.edge_index)\n",
    "        for n in range(n_nodes):\n",
    "            neighbors, _, _, _ = torch_geometric.utils.k_hop_subgraph(\n",
    "                n, self.k, edge_index\n",
    "            )\n",
    "            incidence_1[n, neighbors] = 1\n",
    "        incidence_1 = torch.Tensor(incidence_1).to_sparse_coo()\n",
    "        data_lifted[self.added_fields[0]] = incidence_1\n",
    "        return data_lifted\n",
    "    \n",
    "    \n",
    "class KNearestNeighborsLifting(AbstractLifting):\n",
    "    def __init__(self, k=1):\n",
    "        super().__init__()\n",
    "        self.transform = torch_geometric.transforms.KNNGraph(k)\n",
    "        self.added_fields = [\"hyperedges\"]\n",
    "\n",
    "    def forward(self, batch: torch_geometric.data.Batch) -> torch_geometric.data.Batch:\n",
    "        batch_lifted = copy.copy(batch)\n",
    "        batch_lifted.pos = batch_lifted.x\n",
    "        n_nodes = batch.x.shape[0]\n",
    "        incidence_1 = torch.zeros(n_nodes, n_nodes)\n",
    "        data_temp = self.transform(batch_lifted)\n",
    "        incidence_1[data_temp.edge_index[0],data_temp.edge_index[1]] = 1\n",
    "        incidence_1 = torch.Tensor(incidence_1).to_sparse_coo()\n",
    "        batch_lifted[self.added_fields[0]] = incidence_1\n",
    "        return batch_lifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mutag = torch_geometric.datasets.TUDataset(root=\"../data/graph\", name=\"MUTAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTAG(188)\n",
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "DataBatch(edge_index=[2, 3632], x=[1658, 7], edge_attr=[3632, 4], y=[94], batch=[1658], ptr=[95], pos=[1658, 7], hyperedges=[1658, 1658])\n",
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "DataBatch(edge_index=[2, 3632], x=[1658, 7], edge_attr=[3632, 4], y=[94], batch=[1658], ptr=[95], pos=[1658, 7], hyperedges=[1658, 1658])\n",
      "DataBatch(edge_index=[2, 3810], x=[1713, 7], edge_attr=[3810, 4], y=[94], batch=[1713], ptr=[95], pos=[1713, 7], hyperedges=[1713, 1713])\n",
      "DataBatch(edge_index=[2, 3632], x=[1658, 7], edge_attr=[3632, 4], y=[94], batch=[1658], ptr=[95], pos=[1658, 7], hyperedges=[1658, 1658])\n"
     ]
    }
   ],
   "source": [
    "lift = KNearestNeighborsLifting(k=1)\n",
    "\n",
    "n_graphs = len(data_mutag)\n",
    "loader = torch_geometric.loader.DataLoader(data_mutag, batch_size=int(n_graphs/2))\n",
    "\n",
    "print(data_mutag)\n",
    "\n",
    "for _ in range(3):\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        batch = lift(batch, batch_idx)\n",
    "        print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]))\n",
      "('edge_index', tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]]))\n",
      "('y', tensor([3, 4, 4,  ..., 3, 3, 3]))\n",
      "('train_mask', tensor([ True,  True,  True,  ..., False, False, False]))\n",
      "('val_mask', tensor([False, False, False,  ..., False, False, False]))\n",
      "('test_mask', tensor([False, False, False,  ...,  True,  True,  True]))\n",
      "('batch', tensor([0, 0, 0,  ..., 0, 0, 0]))\n",
      "('ptr', tensor([   0, 2708]))\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    for b in batch:\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "loader_lifted = torch_geometric.loader.DataLoader(data_lifted, batch_size=n_graphs)\n",
    "for d in loader_lifted:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(data_lifted.hyperedges.indices()[1][data_lifted.hyperedges.indices()[0] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cora(cfg):\n",
    "    data_dir = cfg[\"data_dir\"]\n",
    "    print(f\"Loading {cfg['data_domain']} dataset name: {cfg['data_name']}\")\n",
    "\n",
    "    data = torch_geometric.datasets.Planetoid(data_dir, \"Cora\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hypergraph dataset name: cora\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "\n",
    "data_cora = get_cora(config.data)\n",
    "n_graphs = len(data_cora)\n",
    "loader = torch_geometric.loader.DataLoader(data_cora, batch_size=n_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2], hyperedges=[2708, 2708])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    data_lifted = lift(batch)\n",
    "\n",
    "print(data_cora)\n",
    "print(data_lifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,    2,  332, 1454, 1666, 1986])\n"
     ]
    }
   ],
   "source": [
    "print(data_lifted.hyperedges.indices()[1][data_lifted.hyperedges.indices()[0] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'readout_workaround' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['readout_workaround'])`.\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'readout' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['readout'])`.\n"
     ]
    }
   ],
   "source": [
    "model = hydra.utils.instantiate(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(data_lifted.x, data_lifted.hyperedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.1128, 0.0000, 0.0000,  ..., 0.0000, 1.0280, 0.0000],\n",
      "        [1.1101, 0.0000, 0.0000,  ..., 0.0000, 0.8908, 0.0000],\n",
      "        [1.2814, 0.0000, 0.0000,  ..., 0.0000, 1.4679, 0.0000],\n",
      "        ...,\n",
      "        [0.8512, 0.0000, 0.0000,  ..., 0.0000, 1.5145, 0.0000],\n",
      "        [1.0093, 0.0000, 0.0000,  ..., 0.0000, 1.0170, 0.0000],\n",
      "        [1.0837, 0.0000, 0.0000,  ..., 0.0000, 0.9484, 0.1635]],\n",
      "       grad_fn=<MulBackward0>), tensor([[0.0000, 0.0000, 0.8117,  ..., 0.0000, 1.9955, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6481,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.2122, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.6992,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8787,  ..., 0.0000, 1.6070, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8623,  ..., 0.0000, 2.3690, 0.0000]],\n",
      "       grad_fn=<MulBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
