{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch_geometric\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def hetero_load(name, path):\n",
    "    file_name = f'{name}.npz'\n",
    "\n",
    "    data = np.load(os.path.join(path, file_name))\n",
    "\n",
    "    x = torch.tensor(data['node_features'])\n",
    "    y = torch.tensor(data['node_labels'])\n",
    "    edge_index = torch.tensor(data['edges']).T\n",
    "\n",
    "    # Make edge_index undirected\n",
    "    edge_index = torch_geometric.utils.to_undirected(edge_index)\n",
    "\n",
    "    # Remove self-loops\n",
    "    edge_index, _ = torch_geometric.utils.remove_self_loops(edge_index)\n",
    "    \n",
    "    data = torch_geometric.data.Data(x=x, y=y, edge_index=edge_index)\n",
    "    return data\n",
    "\n",
    "def download_hetero_datasets(name, path):\n",
    "    url = 'https://github.com/OpenGSL/HeterophilousDatasets/raw/main/data/'\n",
    "    name = f'{name}.npz'\n",
    "    try:\n",
    "        print(f'Downloading {name}')\n",
    "        path2save = os.path.join(path, name)\n",
    "        urllib.request.urlretrieve(url + name, path2save)\n",
    "        print('Done!')\n",
    "    except:\n",
    "        raise Exception('''Download failed! Make sure you have stable Internet connection and enter the right name''')\n",
    "\n",
    "\n",
    "\n",
    "import os.path as osp\n",
    "from collections.abc import Callable\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.io import fs\n",
    "\n",
    "from topobenchmarkx.io.load.heterophilic import download_hetero_datasets, load_heterophilic_data\n",
    "\n",
    "from topobenchmarkx.io.load.split_utils import random_splitting\n",
    "\n",
    "\n",
    "class HeteroDataset(InMemoryDataset):\n",
    "    r\"\"\"\n",
    "    Dataset class for US County Demographics dataset.\n",
    "\n",
    "    Args:\n",
    "        root (str): Root directory where the dataset will be saved.\n",
    "        name (str): Name of the dataset.\n",
    "        parameters (DictConfig): Configuration parameters for the dataset.\n",
    "        transform (Optional[Callable]): A function/transform that takes in an\n",
    "            `torch_geometric.data.Data` object and returns a transformed version.\n",
    "            The transform function is applied to the loaded data before saving it.\n",
    "        pre_transform (Optional[Callable]): A function/transform that takes in an\n",
    "            `torch_geometric.data.Data` object and returns a transformed version.\n",
    "            The pre_transform function is applied to the data before the transform\n",
    "            function is applied.\n",
    "        pre_filter (Optional[Callable]): A function that takes in an\n",
    "            `torch_geometric.data.Data` object and returns a boolean value\n",
    "            indicating whether the data object should be included in the dataset.\n",
    "        force_reload (bool): If set to True, the dataset will be re-downloaded\n",
    "            even if it already exists on disk. (default: True)\n",
    "        use_node_attr (bool): If set to True, the node attributes will be included\n",
    "            in the dataset. (default: False)\n",
    "        use_edge_attr (bool): If set to True, the edge attributes will be included\n",
    "            in the dataset. (default: False)\n",
    "\n",
    "    Attributes:\n",
    "        URLS (dict): Dictionary containing the URLs for downloading the dataset.\n",
    "        FILE_FORMAT (dict): Dictionary containing the file formats for the dataset.\n",
    "        RAW_FILE_NAMES (dict): Dictionary containing the raw file names for the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RAW_FILE_NAMES = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        name: str,\n",
    "        parameters: DictConfig,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = True,\n",
    "        use_node_attr: bool = False,\n",
    "        use_edge_attr: bool = False,\n",
    "    ) -> None:\n",
    "        self.name = name #.replace(\"_\", \"-\")\n",
    "        self.parameters = parameters\n",
    "        super().__init__(\n",
    "            root, transform, pre_transform, pre_filter, force_reload=force_reload\n",
    "        )\n",
    "\n",
    "        # Step 3:Load the processed data\n",
    "        # After the data has been downloaded from source\n",
    "        # Then preprocessed to obtain x,y and saved into processed folder\n",
    "        # We can now load the processed data from processed folder\n",
    "\n",
    "        # Load the processed data\n",
    "        data, _, _ = fs.torch_load(self.processed_paths[0])\n",
    "\n",
    "        # Map the loaded data into\n",
    "        data = Data.from_dict(data)\n",
    "\n",
    "        # Step 5: Create the splits and upload desired fold\n",
    "        splits = random_splitting(data.y, parameters=self.parameters)\n",
    "\n",
    "        # Assign train val test masks to the graph\n",
    "        data.train_mask = torch.from_numpy(splits[\"train\"])\n",
    "        data.val_mask = torch.from_numpy(splits[\"valid\"])\n",
    "        data.test_mask = torch.from_numpy(splits[\"test\"])\n",
    "\n",
    "        # Assign data object to self.data, to make it be prodessed by Dataset class\n",
    "        self.data, self.slices = self.collate([data])\n",
    "\n",
    "    # Do not forget to take care of properties\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return osp.join(self.root, self.name, \"raw\")\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        return osp.join(self.root, self.name, \"processed\")\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return \"data.pt\"\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self) -> list[str]:\n",
    "        \"\"\"Spefify the downloaded raw fine name\"\"\"\n",
    "        return [f\"{self.name}.npz\"]\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \"\"\"\n",
    "        Downloads the dataset from the specified URL and saves it to the raw directory.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the dataset URL is not found.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Download data from the source\n",
    "        download_hetero_datasets(name=self.name, path=self.raw_dir)\n",
    "\n",
    "    def process(self) -> None:\n",
    "        \"\"\"\n",
    "        Process the data for the dataset.\n",
    "\n",
    "        This method loads the US county demographics data, applies any pre-processing transformations if specified,\n",
    "        and saves the processed data to the appropriate location.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "    \n",
    "        data = load_heterophilic_data(name=self.name, path=self.raw_dir)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        self.save([data], self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}()\"\n",
    "\n",
    "\n",
    "\n",
    "data_dir = '/home/lev/projects/TopoBenchmarkX/datasets'\n",
    "data_domain = 'graph'\n",
    "data_type = 'heterophilic'\n",
    "data_name = 'amazon_ratings'\n",
    "\n",
    "data_dir = f'{data_dir}/{data_domain}/{data_type}'\n",
    "\n",
    "parameters={\n",
    "    'split_type': 'random',\n",
    "    'k': 10,\n",
    "    'train_prop': 0.5,\n",
    "    'data_seed':0,\n",
    "    'data_split_dir': f'/home/lev/projects/TopoBenchmarkX/datasets/data_splits/{data_name}'\n",
    "  }\n",
    "\n",
    "dataset = HeteroDataset(name=data_name, root = data_dir, parameters=parameters, force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
