_target_: topobenchmarkx.models.network_module.NetworkModule

feature_encoder:
  _target_: topobenchmarkx.models.encoders.default_encoders.BaseEdgeFeatureEncoder
  in_channels: ${dataset.parameters.num_features}
  out_channels: ${model.backbone.out_channels}

backbone:
  _target_: topomodelx.nn.cell.can.CAN
  in_channels_0: ${model.backbone.out_channels}
  in_channels_1: ${model.backbone.out_channels}
  out_channels: 128
  dropout: 0.5
  heads: 4 # For now we stuck to out_channels//heads
  concat: True
  skip_connection: True
  n_layers: 2
  att_lift: False

loss:
  _target_: topobenchmarkx.models.losses.loss.DefaultLoss
  task: ${dataset.parameters.task}
  loss_type: ${dataset.parameters.loss_type}

# evaluator:
#   _target_: topobenchmarkx.evaluators.evaluator.Evaluator
#   metrics: [acc, rocauc]

readout:
  _target_: topobenchmarkx.models.readouts.default_readouts.GNNBatchReadOut
  task_level: ${dataset.parameters.task_level}
  in_channels: ${parameter_multiplication:${model.backbone.out_channels},${model.backbone.heads}} #[${model.backbone.heads},  ]
  out_channels: ${dataset.parameters.num_classes}

# readout_workaround:
#   _target_: topobenchmarkx.models.readout_workaround.ReadOutWorkaround
#   backbone_outputs: ["x_0"]


backbone_wrapper:
  _target_: topobenchmarkx.models.wrappers.default_wrapper.CANWrapper
  _partial_: true

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.01
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.PolynomialLR
  _partial_: true
  last_epoch: -1
  total_iters: ${trainer.max_epochs}

# compile model for faster training with pytorch 2.0
compile: false
