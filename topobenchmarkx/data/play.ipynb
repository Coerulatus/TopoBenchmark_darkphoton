{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add manually root '/home/lev/projects/TopoBenchmarkX'\n",
    "root_path = '/home/lev/projects/TopoBenchmarkX'\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "import os.path as osp\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.io import fs, read_tu_data\n",
    "\n",
    "from topobenchmarkx.io.load.download_utils import download_google_drive_datasets\n",
    "\n",
    "class CornelDataset(InMemoryDataset):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    URLS = {'contact-high-school': 'https://drive.google.com/open?id=1VA2P62awVYgluOIh1W4NZQQgkQCBk-Eu'}\n",
    "    file_format = \"tar.gz\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        name: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "        use_node_attr: bool = False,\n",
    "        use_edge_attr: bool = False,\n",
    "        cleaned: bool = False,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.cleaned = cleaned\n",
    "        super().__init__(root, transform, pre_transform, pre_filter,\n",
    "                         force_reload=force_reload)\n",
    "\n",
    "        out = fs.torch_load(self.processed_paths[0])\n",
    "        if not isinstance(out, tuple) or len(out) < 3:\n",
    "            raise RuntimeError(\n",
    "                \"The 'data' object was created by an older version of PyG. \"\n",
    "                \"If this error occurred while loading an already existing \"\n",
    "                \"dataset, remove the 'processed/' directory in the dataset's \"\n",
    "                \"root folder and try again.\")\n",
    "        assert len(out) == 3 or len(out) == 4\n",
    "\n",
    "        if len(out) == 3:  # Backward compatibility.\n",
    "            data, self.slices, self.sizes = out\n",
    "            data_cls = Data\n",
    "        else:\n",
    "            data, self.slices, self.sizes, data_cls = out\n",
    "\n",
    "        if not isinstance(data, dict):  # Backward compatibility.\n",
    "            self.data = data\n",
    "        else:\n",
    "            self.data = data_cls.from_dict(data)\n",
    "\n",
    "        assert isinstance(self._data, Data)\n",
    "        if self._data.x is not None and not use_node_attr:\n",
    "            num_node_attributes = self.num_node_attributes\n",
    "            self._data.x = self._data.x[:, num_node_attributes:]\n",
    "        if self._data.edge_attr is not None and not use_edge_attr:\n",
    "            num_edge_attrs = self.num_edge_attributes\n",
    "            self._data.edge_attr = self._data.edge_attr[:, num_edge_attrs:]\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        name = f'raw{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "        return osp.join(self.root, self.name, name)\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        name = f'processed{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "        return osp.join(self.root, self.name, name)\n",
    "\n",
    "    @property\n",
    "    def num_node_labels(self) -> int:\n",
    "        return self.sizes['num_node_labels']\n",
    "\n",
    "    @property\n",
    "    def num_node_attributes(self) -> int:\n",
    "        return self.sizes['num_node_attributes']\n",
    "\n",
    "    @property\n",
    "    def num_edge_labels(self) -> int:\n",
    "        return self.sizes['num_edge_labels']\n",
    "\n",
    "    @property\n",
    "    def num_edge_attributes(self) -> int:\n",
    "        return self.sizes['num_edge_attributes']\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        names = ['A', 'graph_indicator']\n",
    "        return [f'{self.name}_{name}.txt' for name in names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \n",
    "        self.url = self.URLS[self.name] \n",
    "        \n",
    "        download_google_drive_datasets(\n",
    "            self.url, \n",
    "            path_to_save=self.raw_dir, \n",
    "            dataset_name=self.name,\n",
    "            file_format=self.file_format\n",
    "        )\n",
    "\n",
    "        fs.cp(f'{self.raw_dir}/{self.name}.{self.file_format}', self.raw_dir, extract=True)\n",
    "        \n",
    "        # url = self.cleaned_url if self.cleaned else self.url\n",
    "        # fs.cp(f'{url}/{self.name}.zip', self.raw_dir, extract=True)\n",
    "\n",
    "        \n",
    "        for filename in fs.ls(osp.join(self.raw_dir, self.name)):\n",
    "            fs.mv(filename, osp.join(self.raw_dir, osp.basename(filename)))\n",
    "        fs.rm(osp.join(self.raw_dir, self.name))\n",
    "\n",
    "        # Delete also f'{self.raw_dir}/{self.name}.{self.file_format}'\n",
    "        fs.rm(f'{self.raw_dir}/{self.name}.{self.file_format}')\n",
    "\n",
    "    def process(self) -> None:\n",
    "        self.data, self.slices, sizes = read_tu_data(self.raw_dir, self.name)\n",
    "\n",
    "        if self.pre_filter is not None or self.pre_transform is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "            self._data_list = None  # Reset cache.\n",
    "\n",
    "        assert isinstance(self._data, Data)\n",
    "        fs.torch_save(\n",
    "            (self._data.to_dict(), self.slices, sizes, self._data.__class__),\n",
    "            self.processed_paths[0],\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.name}({len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lev/projects/TopoBenchmarkX/datasets/graph/contact-high-school/raw/contact-high-school_A.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m CornelDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/lev/projects/TopoBenchmarkX/datasets/graph\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontact-high-school\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 36\u001b[0m, in \u001b[0;36mCornelDataset.__init__\u001b[0;34m(self, root, name, transform, pre_transform, pre_filter, force_reload, use_node_attr, use_edge_attr, cleaned)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaned \u001b[38;5;241m=\u001b[39m cleaned\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform, pre_transform, pre_filter,\n\u001b[1;32m     37\u001b[0m                  force_reload\u001b[38;5;241m=\u001b[39mforce_reload)\n\u001b[1;32m     39\u001b[0m out \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mtorch_load(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:81\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     force_reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform, pre_transform, pre_filter, log,\n\u001b[1;32m     82\u001b[0m                      force_reload)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data: Optional[BaseData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/torch_geometric/data/dataset.py:115\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process()\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/torch_geometric/data/dataset.py:260\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m    259\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[1;32m    262\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m fs\u001b[38;5;241m.\u001b[39mtorch_save(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[0;32mIn[18], line 127\u001b[0m, in \u001b[0;36mCornelDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices, sizes \u001b[38;5;241m=\u001b[39m read_tu_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m         data_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/torch_geometric/io/tu.py:25\u001b[0m, in \u001b[0;36mread_tu_data\u001b[0;34m(folder, prefix)\u001b[0m\n\u001b[1;32m     22\u001b[0m files \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mglob(osp\u001b[38;5;241m.\u001b[39mjoin(folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_*.txt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     23\u001b[0m names \u001b[38;5;241m=\u001b[39m [osp\u001b[38;5;241m.\u001b[39mbasename(f)[\u001b[38;5;28mlen\u001b[39m(prefix) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[0;32m---> 25\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m read_file(folder, prefix, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     26\u001b[0m batch \u001b[38;5;241m=\u001b[39m read_file(folder, prefix, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph_indicator\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mlong) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m node_attribute \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/torch_geometric/io/tu.py:100\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(folder, prefix, name, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(\n\u001b[1;32m     94\u001b[0m     folder: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     95\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     96\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     97\u001b[0m     dtype: Optional[torch\u001b[38;5;241m.\u001b[39mdtype] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     99\u001b[0m     path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_txt_array(path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/torch_geometric/io/txt_array.py:31\u001b[0m, in \u001b[0;36mread_txt_array\u001b[0;34m(path, sep, start, end, dtype, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_txt_array\u001b[39m(\n\u001b[1;32m     24\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     25\u001b[0m     sep: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     32\u001b[0m         src \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_txt_array(src, sep, start, end, dtype, device)\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/fsspec/core.py:103\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    101\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobjects \u001b[38;5;241m=\u001b[39m [f]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/fsspec/spec.py:1293\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1293\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[1;32m   1294\u001b[0m         path,\n\u001b[1;32m   1295\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   1296\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[1;32m   1297\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[1;32m   1298\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1300\u001b[0m     )\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/fsspec/implementations/local.py:184\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/fsspec/implementations/local.py:306\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[0;32m~/miniconda3/envs/topo/lib/python3.11/site-packages/fsspec/implementations/local.py:311\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    313\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lev/projects/TopoBenchmarkX/datasets/graph/contact-high-school/raw/contact-high-school_A.txt'"
     ]
    }
   ],
   "source": [
    "a = CornelDataset(root='/home/lev/projects/TopoBenchmarkX/datasets/graph', name='contact-high-school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
