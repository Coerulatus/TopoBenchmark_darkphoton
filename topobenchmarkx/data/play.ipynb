{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add manually root '/home/lev/projects/TopoBenchmarkX'\n",
    "root_path = '/home/lev/projects/TopoBenchmarkX'\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "import os.path as osp\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.io import fs, read_tu_data\n",
    "\n",
    "from topobenchmarkx.io.load.download_utils import download_file_from_drive\n",
    "\n",
    "class CornelDataset(InMemoryDataset):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    URLS = {\n",
    "        'contact-high-school': 'https://drive.google.com/open?id=1VA2P62awVYgluOIh1W4NZQQgkQCBk-Eu',\n",
    "        'US-county-demos': 'https://drive.google.com/file/d/1FNF_LbByhYNICPNdT6tMaJI9FxuSvvLK/view?usp=sharing',\n",
    "    }\n",
    "\n",
    "    FILE_FORMAT = {\n",
    "        'contact-high-school': 'tar.gz',\n",
    "        'US-county-demos': 'zip',\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        name: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "        use_node_attr: bool = False,\n",
    "        use_edge_attr: bool = False,\n",
    "        cleaned: bool = False,\n",
    "    ) -> None:\n",
    "        self.name = name.replace('_', '-')\n",
    "        self.cleaned = cleaned\n",
    "        super().__init__(root, transform, pre_transform, pre_filter,\n",
    "                         force_reload=force_reload)\n",
    "\n",
    "        self.data, _, _ = fs.torch_load(self.processed_paths[0])\n",
    "        \n",
    "        # if not isinstance(out, tuple) or len(out) < 3:\n",
    "        #     raise RuntimeError(\n",
    "        #         \"The 'data' object was created by an older version of PyG. \"\n",
    "        #         \"If this error occurred while loading an already existing \"\n",
    "        #         \"dataset, remove the 'processed/' directory in the dataset's \"\n",
    "        #         \"root folder and try again.\")\n",
    "        # assert len(out) == 3 or len(out) == 4\n",
    "\n",
    "        # if len(out) == 3:  # Backward compatibility.\n",
    "        #     data, self.slices, self.sizes = out\n",
    "        #     data_cls = Data\n",
    "        # else:\n",
    "        #     data, self.slices, self.sizes, data_cls = out\n",
    "\n",
    "        # if not isinstance(data, dict):  # Backward compatibility.\n",
    "        #     self.data = data\n",
    "        # else:\n",
    "        #     self.data = data_cls.from_dict(data)\n",
    "\n",
    "        # assert isinstance(self._data, Data)\n",
    "        # if self._data.x is not None and not use_node_attr:\n",
    "        #     num_node_attributes = self.num_node_attributes\n",
    "        #     self._data.x = self._data.x[:, num_node_attributes:]\n",
    "        # if self._data.edge_attr is not None and not use_edge_attr:\n",
    "        #     num_edge_attrs = self.num_edge_attributes\n",
    "        #     self._data.edge_attr = self._data.edge_attr[:, num_edge_attrs:]\n",
    "\n",
    "    # @property\n",
    "    # def raw_dir(self) -> str:\n",
    "    #     name = f'raw{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "    #     return osp.join(self.root, self.name, name)\n",
    "\n",
    "    # @property\n",
    "    # def processed_dir(self) -> str:\n",
    "    #     name = f'processed{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "    #     return osp.join(self.root, self.name, name)\n",
    "\n",
    "    # @property\n",
    "    # def num_node_labels(self) -> int:\n",
    "    #     return self.sizes['num_node_labels']\n",
    "\n",
    "    # @property\n",
    "    # def num_node_attributes(self) -> int:\n",
    "    #     return self.sizes['num_node_attributes']\n",
    "\n",
    "    # @property\n",
    "    # def num_edge_labels(self) -> int:\n",
    "    #     return self.sizes['num_edge_labels']\n",
    "\n",
    "    # @property\n",
    "    # def num_edge_attributes(self) -> int:\n",
    "    #     return self.sizes['num_edge_attributes']\n",
    "\n",
    "    # @property\n",
    "    # def raw_file_names(self) -> List[str]:\n",
    "    #     names = ['A', 'graph_indicator']\n",
    "    #     return [f'{self.name}_{name}.txt' for name in names]\n",
    "\n",
    "    # @property\n",
    "    # def processed_file_names(self) -> str:\n",
    "    #     return 'data.pt'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        # Download data\n",
    "        self.url = self.URLS[self.name] \n",
    "        self.file_format = self.FILE_FORMAT[self.name]\n",
    "        \n",
    "        download_file_from_drive(\n",
    "            file_link=self.url, \n",
    "            path_to_save=self.raw_dir, \n",
    "            dataset_name=self.name,\n",
    "            file_format=self.file_format\n",
    "        )\n",
    "\n",
    "        fs.cp(f'{self.raw_dir}/{self.name}.{self.file_format}', self.raw_dir, extract=True)\n",
    "\n",
    "        # Move into raw/\n",
    "        for filename in fs.ls(osp.join(self.raw_dir, self.name)):\n",
    "            fs.mv(filename, osp.join(self.raw_dir, osp.basename(filename)))\n",
    "        fs.rm(osp.join(self.raw_dir, self.name))\n",
    "\n",
    "        # Delete also f'{self.raw_dir}/{self.name}.{self.file_format}'\n",
    "        fs.rm(f'{self.raw_dir}/{self.name}.{self.file_format}')\n",
    "\n",
    "    def process(self) -> None:\n",
    "        data = load_us_county_demos(self.raw_dir, self.name)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        self.save([data], self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.name}({len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "def load_us_county_demos(path, dataset_name, year=2012):\n",
    "\n",
    "    edges_df = pd.read_csv(f'{path}/county_graph.csv')\n",
    "    stat = pd.read_csv(f'{path}/county_stats_{year}.csv', encoding='ISO-8859-1')\n",
    "    \n",
    "    keep_cols = ['FIPS', 'DEM', 'GOP', 'MedianIncome', 'MigraRate', 'BirthRate', 'DeathRate', 'BachelorRate', 'UnemploymentRate']\n",
    "    # Drop rows with missing values\n",
    "    stat = stat[keep_cols].dropna()\n",
    "\n",
    "    # Delete edges that are not present in stat df\n",
    "    unique_fips = stat['FIPS'].unique()\n",
    "\n",
    "    src_ = edges_df['SRC'].apply(lambda x: x in unique_fips) \n",
    "    dst_ = edges_df['DST'].apply(lambda x: x in unique_fips)\n",
    "\n",
    "    edges_df = edges_df[src_ & dst_]\n",
    "\n",
    "    # Remove rows from stat df where edges_df['SRC'] or edges_df['DST'] are not present\n",
    "    stat = stat[stat['FIPS'].isin(edges_df['SRC']) & stat['FIPS'].isin(edges_df['DST'])]\n",
    "    stat = stat.reset_index(drop=True)\n",
    "\n",
    "    # Remove rows where SRC == DST\n",
    "    edges_df = edges_df[edges_df['SRC'] != edges_df['DST']]\n",
    "\n",
    "    # Get torch_geometric edge_index format\n",
    "    edge_index = torch.tensor(np.stack([edges_df['SRC'].to_numpy(), edges_df['DST'].to_numpy()]))\n",
    "\n",
    "    # Make edge_index undirected\n",
    "    edge_index = torch_geometric.utils.to_undirected(edge_index)\n",
    "\n",
    "    # Convert edge_index back to pandas DataFrame\n",
    "    edges_df = pd.DataFrame(edge_index.numpy().T, columns=['SRC', 'DST'])\n",
    "\n",
    "    del edge_index\n",
    "\n",
    "    # Map stat['FIPS'].unique() to [0, ..., num_nodes]\n",
    "    fips_map = {fips: i for i, fips in enumerate(stat['FIPS'].unique())}\n",
    "    stat['FIPS'] = stat['FIPS'].map(fips_map)\n",
    "\n",
    "    # Map edges_df['SRC'] and edges_df['DST'] to [0, ..., num_nodes]\n",
    "    edges_df['SRC'] = edges_df['SRC'].map(fips_map)\n",
    "    edges_df['DST'] = edges_df['DST'].map(fips_map)\n",
    "\n",
    "    # Get torch_geometric edge_index format\n",
    "    edge_index = torch.tensor(np.stack([edges_df['SRC'].to_numpy(), edges_df['DST'].to_numpy()]))\n",
    "\n",
    "    # Remove isolated nodes (Note: this function maps the nodes to [0, ..., num_nodes] automatically)\n",
    "    edge_index, _, mask = torch_geometric.utils.remove_isolated_nodes(edge_index)\n",
    "\n",
    "    # Conver mask to index\n",
    "    index = np.arange(mask.size(0))[mask]\n",
    "    stat = stat.iloc[index]\n",
    "    stat = stat.reset_index(drop=True)\n",
    "\n",
    "    # Get new values for FIPS from current index\n",
    "    # To understand why please print stat.iloc[[516, 517, 518, 519, 520]] for 2012 year\n",
    "    # Basically the FIPS values has been shifted\n",
    "    stat['FIPS'] = stat.reset_index()['index']\n",
    "\n",
    "    # Create Election variable\n",
    "    stat['Election'] = (stat['DEM'] - stat['GOP']) / (stat['DEM'] + stat['GOP'])\n",
    "\n",
    "    # Drop DEM and GOP columns and FIPS\n",
    "    stat = stat.drop(columns=['DEM', 'GOP', 'FIPS'])\n",
    "\n",
    "    # Prediction col\n",
    "    y_col = 'Election' # TODO: Define through config file\n",
    "    x_col = list(set(stat.columns).difference(set([y_col])))\n",
    "\n",
    "    stat['MedianIncome'] = stat['MedianIncome'].apply(lambda x: x.replace(',', '')).to_numpy().astype(float)\n",
    "\n",
    "    x = stat[x_col].to_numpy()\n",
    "    y = stat[y_col].to_numpy()\n",
    "\n",
    "\n",
    "    data = torch_geometric.data.Data(x=x, y=y, edge_index=edge_index)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "a = CornelDataset(root='/home/lev/projects/TopoBenchmarkX/datasets/graph', name='US-county-demos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': array([[ 6.9000e+00,  2.1900e+01,  1.1100e+01,  1.0200e+01,  5.1441e+04,\n",
       "          -6.1000e+00],\n",
       "         [ 7.5000e+00,  2.8600e+01,  1.1100e+01,  1.0000e+01,  4.8867e+04,\n",
       "           1.7600e+01],\n",
       "         [ 1.1500e+01,  1.3600e+01,  1.1000e+01,  1.0700e+01,  3.0287e+04,\n",
       "          -6.8000e+00],\n",
       "         ...,\n",
       "         [ 5.6000e+00,  1.8700e+01,  1.4800e+01,  5.5000e+00,  6.1057e+04,\n",
       "          -4.5000e+00],\n",
       "         [ 5.2000e+00,  2.1200e+01,  1.0700e+01,  1.2500e+01,  4.9533e+04,\n",
       "          -3.0000e+00],\n",
       "         [ 4.1000e+00,  1.6800e+01,  1.0400e+01,  9.4000e+00,  5.3665e+04,\n",
       "          -1.0400e+01]]),\n",
       "  'edge_index': tensor([[   0,    0,    0,  ..., 3106, 3106, 3106],\n",
       "          [  10,   23,   25,  ..., 3088, 3089, 3097]]),\n",
       "  'y': array([-0.46424958, -0.56411933,  0.02926744, ..., -0.60490232,\n",
       "         -0.58287365, -0.73974715])},\n",
       " None,\n",
       " torch_geometric.data.data.Data)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
