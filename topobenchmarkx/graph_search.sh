# GCN
python train.py dataset=cocitation_cora model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun #tags "[first_tag, second_tag]"
python train.py dataset=cocitation_citeseer model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun
python train.py dataset=cocitation_pubmed model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun
python train.py dataset=PROTEINS_TU model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 dataset.parameters.batch_size=128,256 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun
python train.py dataset=NCI1 model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 dataset.parameters.batch_size=128,256 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun

# python train.py dataset=IMDB-BINARY model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 dataset.parameters.batch_size=128,256 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun
# python train.py dataset=IMDB-MULTI model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 dataset.parameters.batch_size=128,256 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun
python train.py dataset=MUTAG model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 dataset.parameters.batch_size=32,64 logger.wandb.project=topobenchmark_22Apr2024 trainer=cpu --multirun
python train.py dataset=ZINC model=graph/gcn model.optimizer.lr=0.01,0.001 model.optimizer.weight_decay=0 model.backbone.hidden_channels=16,32,64,128 model.backbone.num_layers=1,2,3,4 dataset.parameters.batch_size=128,256 dataset.parameters.data_seed=0 model.backbone.dropout=0,0.25,0.5 logger.wandb.project=topobenchmark_22Apr2024 callbacks.early_stopping.patience=10 trainer=default --multirun
python train.py dataset=REDDIT-BINARY model=graph/gcn model.optimizer.lr=0.01,0.001 model.backbone.hidden_channels=64,128,256 model.backbone.num_layers=1,2,3,4 dataset.parameters.data_seed=0,3,5 model.backbone.dropout=0,0.25,0.5 callbacks.early_stopping.patience=10 dataset.parameters.data_seed=0,3,5 dataset.parameters.batch_size=128,256 logger.wandb.project=topobenchmark_22Apr2024 trainer=default --multirun


